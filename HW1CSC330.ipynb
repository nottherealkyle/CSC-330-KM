{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "| Trial | Temperature (T) | Predicted Behavior| Model Response | Model Coherence |\n",
        "| -------- | ------- | --- | --- | --- |\n",
        "| A | 0.1 | Conservative | Hello, I am from the United States. I am a citizen of the United States of America. I am a citizen of | 10 |\n",
        "| B | 0.8 | Creative | Hello, I am from a far off land. I'm the son of an aristocrat, a wealthy merchant of many countries | 9 |\n",
        "| C | 2.0 | Chaos | Hello, I am from Denmark. If you are interested in a bit of advice as this website is often an issue you can | 3 |"
      ],
      "metadata": {
        "id": "-8IYC5xQ2OAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis:\n",
        "\n",
        "\n",
        "1.   Did your model repeat any words or phrases?\n",
        "  \n",
        "  Trial A did repeat the majority of the tokens it produced, while trials B and C did not repeat. This is because the low temperature of A made the model always choose the most likely predicition, unlike B and C which are less and less certain on choosing the next token respectively.\n",
        "\n",
        "2.   Did the model use real words, or did it start outputting random characters and punctuation? Explain how the \"Probability Distribution\" changed to allow this.\n",
        "\n",
        " As the temperature increased, the model began outputting random tokens especially in trial C. The probability distribution changed to allows this due to the temperature being attached to the softmax equation, where a higher temperture evens out the output of softmax so that the probabilities of the tokens being chosen are more equal to one another, while a lower temperature makes it more likely that the token with the highest probability is chosen.\n",
        "\n",
        " 3. If you were building a medical AI to give prescriptions or advice, which temperature would you use?\n",
        "\n",
        " If I was building a medical AI to give perscriptions or advice where precision is important to the model, I would use a very low temperature such as 0.1 or 0.2, where it will always choose the most likely diagnosis given the symptoms.\n",
        "\n",
        " 4. If you were building an AI to write a surrealist dream-journal, which would you use?\n",
        "\n",
        " If I were building an AI to write a surrealist dream-journal, I would use a higher temperature around 0.8-0.9, because this will allow the model to choose more interesting and random tokens that seem more creative tio readers, while being able to retain a semblance of sense in its grammer and writing.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9gLB514B5eAM"
      }
    }
  ]
}